{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モジュールのインポート\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import keras\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像にノイズを加える関数\n",
    "\n",
    "\n",
    "def add_noise(image, percentage):\n",
    "    noisy_image = copy.deepcopy(image)\n",
    "    mask = np.random.random(image.shape) < percentage\n",
    "    noise = np.random.randint(0, 256, size=image.shape)\n",
    "    noise_float = noise / 255.0\n",
    "    noisy_image[mask] = noise_float[mask]\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットのインポート\n",
    "\n",
    "mnist = fetch_openml(\"mnist_784\", as_frame=False, version=1, parser=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの調整\n",
    "\n",
    "X, y = mnist.data, mnist.target\n",
    "\n",
    "# 0~1の浮動小数に変換\n",
    "X = X / 255.0\n",
    "\n",
    "# yをone-hot-encoding\n",
    "y = y.astype(int)\n",
    "num_labels = len(np.unique(y))\n",
    "one_hot_target = np.zeros((X.shape[0], num_labels))\n",
    "one_hot_target[range(X.shape[0]), y] = 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X[:3000], one_hot_target[:3000], test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# サイズの確認\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100, 784)\n",
      "(2100, 784)\n"
     ]
    }
   ],
   "source": [
    "# 訓練データにノイズを加える\n",
    "percentage = 0.10\n",
    "\n",
    "X_train_noise = [add_noise(image, percentage) for image in X_train]\n",
    "X_train_noise = np.array(X_train_noise)\n",
    "\n",
    "# サイズの確認\n",
    "print(X_train_noise.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu関数とSoftmax関数\n",
    "\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            self.mask = x <= 0\n",
    "            out = x.copy()\n",
    "            out[self.mask] = 0\n",
    "        else:\n",
    "            out = np.maximum(0, x)\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        if isinstance(dout, np.ndarray):\n",
    "            self.mask = dout <= 0\n",
    "            dx = np.ones_like(dout)\n",
    "            dx[self.mask] = 0\n",
    "        else:\n",
    "            dx = 1 if dout > 0 else 0\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        exp_x = np.exp(x - np.max(x))\n",
    "        sum_exp_x = np.sum(exp_x)\n",
    "        out = exp_x / sum_exp_x\n",
    "        self.out = out\n",
    "        return np.clip(out, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (self.out * (1 - self.out))\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワーク\n",
    "class Neural_Network:\n",
    "    def __init__(self, hid_unit, learning_rate):\n",
    "        self.hid_unit = hid_unit\n",
    "        in_unit = 784\n",
    "        out_unit = 10\n",
    "\n",
    "        limit1 = np.sqrt(2.0 / in_unit)\n",
    "        limit2 = np.sqrt(2.0 / self.hid_unit)\n",
    "        self.weights1_2 = np.random.randn(in_unit, self.hid_unit) * limit1\n",
    "        self.weights2_3 = np.random.randn(self.hid_unit, out_unit) * limit2\n",
    "\n",
    "        self.bias1 = np.zeros((1, self.hid_unit))\n",
    "        self.bias2 = np.zeros((1, out_unit))\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.relu = Relu()\n",
    "        self.softmax = Softmax()\n",
    "\n",
    "    # フィードフォワード\n",
    "    def Feedforward(self, X):\n",
    "        self.hid_layer = self.relu.forward(np.dot(X, self.weights1_2) + self.bias1)\n",
    "        output = self.softmax.forward(\n",
    "            np.dot(self.hid_layer, self.weights2_3) + self.bias2\n",
    "        )\n",
    "        return output\n",
    "\n",
    "    # 誤差逆伝播法\n",
    "    def Back_propagation(self, X, y):\n",
    "        output = self.Feedforward(X)\n",
    "        delta_output = (y - output) * self.softmax.backward(output)\n",
    "        # delta_output = y - output\n",
    "        delta_hidden = np.dot(delta_output, self.weights2_3.T) * self.relu.backward(\n",
    "            self.hid_layer\n",
    "        )\n",
    "\n",
    "        # 重みとバイアスの更新\n",
    "        self.weights2_3 -= self.learning_rate * np.dot(self.hid_layer.T, delta_output)\n",
    "        self.weights1_2 -= self.learning_rate * np.dot(X.T, delta_hidden)\n",
    "        self.bias2 -= self.learning_rate * np.sum(delta_output, axis=0, keepdims=True)\n",
    "        self.bias1 -= self.learning_rate * np.sum(delta_hidden, axis=0, keepdims=True)\n",
    "\n",
    "    # バッチを用いた学習\n",
    "    def train(self, X_train, y_train, epochs, batch_size):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                X_batch = X_train[i : i + batch_size]\n",
    "                y_batch = y_train[i : i + batch_size]\n",
    "\n",
    "                self.Back_propagation(X_batch, y_batch)\n",
    "\n",
    "                # バッチごとの損失\n",
    "                output = self.Feedforward(X_batch)\n",
    "                output = np.clip(output, 1e-15, 1 - 1e-15)\n",
    "                batch_loss = -np.sum(y_batch * np.log(output))\n",
    "                print(f\"Epoch {epoch}, Batch {i // batch_size}: Loss {batch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチ学習\n",
    "\n",
    "hid_unit = 50\n",
    "learning_rate = 0.001\n",
    "epochs = 200\n",
    "batch_size = 40\n",
    "model_batch = Neural_Network(hid_unit, learning_rate)\n",
    "\n",
    "model_batch.train(X_train_noise, y_train, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習\n",
    "\n",
    "epochs = 2000\n",
    "hid_unit = 40\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = Neural_Network(hid_unit, learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.Feedforward(X_train_noise)\n",
    "    model.Back_propagation(X_train_noise, y_train)\n",
    "\n",
    "# テストデータでモデルを評価\n",
    "predictions = model.Feedforward(X_test)\n",
    "accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))\n",
    "print(f\"テストデータの正解率: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
